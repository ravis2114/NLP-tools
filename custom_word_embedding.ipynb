{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['India has a large young population that is skilled and eager to adopt AI',\n",
    "            'The country has been ranked second on the Stanford AI Vibrancy Index primarily on account of its large AI-trained workforce',\n",
    "            'The RAISE 2020 summit (Responsible AI for Social Empowerment) has brought issues around artificial intelligence to the centre of policy discussions',\n",
    "            'Countries across the world are making efforts to be part of the AI-led digital economy, which is estimated to contribute around $15.7 trillion to the global economy by 2030',\n",
    "            'India, with its “AI for All” strategy, a vast pool of AI-trained workforce and an emerging startup ecosystem, has a unique opportunity to be a major contributor to AI-driven solutions that can revolutionise healthcare, agriculture, manufacturing, education and skilling',\n",
    "            'AI is the branch of computer science concerned with developing machines that can complete tasks that typically require human intelligence',\n",
    "            'With the explosion of available data expansion of computing capacity, the world is witnessing rapid advancements in AI, machine learning and deep learning, transforming almost all sectors of the economy',\n",
    "            'Machine Learning-based deep-learning algorithms in AI can give insights to healthcare providers in predicting future events for patients',\n",
    "            'It can also aid in the early detection and prevention of diseases by capturing the vitals of patients',\n",
    "            'AI-based solutions on water management, crop insurance and pest control are also being developed',\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Vocabulary size\n",
    "vocab_size=10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one hot------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5797, 5807, 8015, 9879, 8879, 5088, 250, 7679, 4275, 7201, 9469, 3123, 7996, 4497], [7578, 9442, 5807, 5155, 9940, 8692, 2362, 7578, 1134, 4497, 5706, 3751, 257, 2362, 3841, 8044, 3817, 9879, 4497, 6408, 3426], [7578, 2967, 9592, 1560, 5717, 4497, 7023, 4747, 1797, 5807, 7412, 4814, 1669, 5084, 4559, 3123, 7578, 934, 8044, 7251, 3691], [1359, 5571, 7578, 5223, 7808, 8837, 8009, 3123, 1874, 4504, 8044, 7578, 4497, 3945, 6292, 3841, 6213, 7679, 6899, 3123, 6418, 1669, 9931, 3942, 7871, 3123, 7578, 6857, 3841, 7994, 216], [5797, 7930, 3817, 4974, 7023, 3666, 5199, 8015, 8503, 1284, 8044, 4497, 6408, 3426, 7201, 5449, 9714, 4945, 8702, 5807, 8015, 1508, 8648, 3123, 1874, 8015, 7902, 6509, 3123, 4497, 1812, 1359, 250, 7008, 7996, 5015, 862, 9040, 1322, 7201, 2457], [4497, 7679, 7578, 2613, 8044, 7177, 7577, 5555, 7930, 9830, 6076, 250, 7008, 1330, 3669, 250, 4209, 7096, 5254, 4559], [7930, 7578, 142, 8044, 3546, 506, 1965, 8044, 7357, 3338, 7578, 5223, 7679, 9166, 6924, 9287, 1312, 4497, 9164, 7817, 7201, 9639, 7817, 8384, 9640, 763, 3911, 8044, 7578, 3841], [9164, 7817, 4268, 9639, 7817, 9237, 1312, 4497, 7008, 8539, 8953, 3123, 5015, 317, 1312, 5424, 2316, 3178, 7023, 4853], [8526, 7008, 2825, 8312, 1312, 7578, 9635, 7765, 7201, 5479, 8044, 6009, 7994, 8673, 7578, 539, 8044, 4853], [4497, 4268, 1359, 2362, 4925, 1228, 340, 6397, 7201, 959, 6678, 7808, 2825, 4125, 2201]]\n"
     ]
    }
   ],
   "source": [
    "onehot_repr=[one_hot(words,vocab_size)for words in sentences] \n",
    "print(onehot_repr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Flatten\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0 5797 5807 8015\n",
      " 9879 8879 5088  250 7679 4275 7201 9469 3123 7996 4497]\n"
     ]
    }
   ],
   "source": [
    "sent_length=25\n",
    "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
    "print(embedded_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=10 #embedding feature dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size,10,input_length=sent_length))\n",
    "model.add(Flatten())\n",
    "model.compile('adam','mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'embedding/embeddings:0' shape=(10000, 10) dtype=float32, numpy=\n",
       " array([[-0.00176504,  0.04047993, -0.02055639, ..., -0.00335064,\n",
       "          0.02489269, -0.04020048],\n",
       "        [-0.01774243,  0.02494733,  0.03743701, ..., -0.01410233,\n",
       "         -0.02627703, -0.04606737],\n",
       "        [-0.01090932, -0.0372359 , -0.02577791, ...,  0.00581222,\n",
       "          0.00990876,  0.02049806],\n",
       "        ...,\n",
       "        [ 0.04154957,  0.01121111, -0.03432702, ..., -0.00771948,\n",
       "          0.04468589,  0.04394935],\n",
       "        [-0.02801621,  0.02302002, -0.03877498, ...,  0.04212922,\n",
       "         -0.00244898,  0.01010113],\n",
       "        [ 0.04240462, -0.02098734,  0.02480968, ..., -0.03099889,\n",
       "         -0.01544229, -0.02346898]], dtype=float32)>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 25, 10)            100000    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 250)               0         \n",
      "=================================================================\n",
      "Total params: 100,000\n",
      "Trainable params: 100,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 25, 10) dtype=float32 (created by layer 'embedding')>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[layer.output for layer in model.layers]\n",
    "model.layers[0].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 250)\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(embedded_docs).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
